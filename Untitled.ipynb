{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2557b4d-ccc9-40d5-8602-7485b867c4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: omz_downloader [-h] [--name PAT[,PAT...]] [--list FILE.LST] [--all]\n",
      "                      [--print_all] [--precisions PREC[,PREC...]] [-o DIR]\n",
      "                      [--cache_dir DIR] [--num_attempts N]\n",
      "                      [--progress_format {text,json}] [-j N]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --name PAT[,PAT...]   download only models whose names match at least one of\n",
      "                        the specified patterns\n",
      "  --list FILE.LST       download only models whose names match at least one of\n",
      "                        the patterns in the specified file\n",
      "  --all                 download all available models\n",
      "  --print_all           print all available models\n",
      "  --precisions PREC[,PREC...]\n",
      "                        download only models with the specified precisions\n",
      "                        (actual for DLDT networks); specify one or more of:\n",
      "                        FP16-INT8,FP32-INT1,FP16,FP16-INT1,FP32,FP32-INT8\n",
      "  -o DIR, --output_dir DIR\n",
      "                        path where to save models\n",
      "  --cache_dir DIR       directory to use as a cache for downloaded files\n",
      "  --num_attempts N      attempt each download up to N times\n",
      "  --progress_format {text,json}\n",
      "                        which format to use for progress reporting\n",
      "  -j N, --jobs N        how many downloads to perform concurrently\n"
     ]
    }
   ],
   "source": [
    "!omz_downloader -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "593dac25-685b-4349-be96-06781fca3770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aclnet\n",
      "aclnet-int8\n",
      "action-recognition-0001\n",
      "age-gender-recognition-retail-0013\n",
      "anti-spoof-mn3\n",
      "asl-recognition-0004\n",
      "background-matting-mobilenetv2\n",
      "bert-base-ner\n",
      "bert-large-uncased-whole-word-masking-squad-0001\n",
      "bert-large-uncased-whole-word-masking-squad-emb-0001\n",
      "bert-large-uncased-whole-word-masking-squad-int8-0001\n",
      "bert-small-uncased-whole-word-masking-squad-0001\n",
      "bert-small-uncased-whole-word-masking-squad-0002\n",
      "bert-small-uncased-whole-word-masking-squad-emb-int8-0001\n",
      "bert-small-uncased-whole-word-masking-squad-int8-0002\n",
      "brain-tumor-segmentation-0002\n",
      "cocosnet\n",
      "colorization-siggraph\n",
      "colorization-v2\n",
      "common-sign-language-0001\n",
      "common-sign-language-0002\n",
      "convnext-tiny\n",
      "ctdet_coco_dlav0_512\n",
      "ctpn\n",
      "deeplabv3\n",
      "densenet-121-tf\n",
      "detr-resnet50\n",
      "dla-34\n",
      "driver-action-recognition-adas-0002\n",
      "drn-d-38\n",
      "efficientdet-d0-tf\n",
      "efficientdet-d1-tf\n",
      "efficientnet-b0\n",
      "efficientnet-b0-pytorch\n",
      "efficientnet-v2-b0\n",
      "efficientnet-v2-s\n",
      "emotions-recognition-retail-0003\n",
      "erfnet\n",
      "f3net\n",
      "face-detection-0200\n",
      "face-detection-0202\n",
      "face-detection-0204\n",
      "face-detection-0205\n",
      "face-detection-0206\n",
      "face-detection-adas-0001\n",
      "face-detection-retail-0004\n",
      "face-detection-retail-0005\n",
      "face-recognition-resnet100-arcface-onnx\n",
      "face-reidentification-retail-0095\n",
      "faceboxes-pytorch\n",
      "facenet-20180408-102900\n",
      "facial-landmarks-35-adas-0002\n",
      "facial-landmarks-98-detection-0001\n",
      "fast-neural-style-mosaic-onnx\n",
      "faster-rcnn-resnet101-coco-sparse-60-0001\n",
      "faster_rcnn_inception_resnet_v2_atrous_coco\n",
      "faster_rcnn_resnet50_coco\n",
      "fastseg-large\n",
      "fastseg-small\n",
      "fbcnn\n",
      "fcrn-dp-nyu-depth-v2-tf\n",
      "formula-recognition-medium-scan-0001\n",
      "formula-recognition-polynomials-handwritten-0001\n",
      "forward-tacotron\n",
      "gaze-estimation-adas-0002\n",
      "gmcnn-places2-tf\n",
      "googlenet-v1-tf\n",
      "googlenet-v2-tf\n",
      "googlenet-v3\n",
      "googlenet-v3-pytorch\n",
      "googlenet-v4-tf\n",
      "gpt-2\n",
      "handwritten-english-recognition-0001\n",
      "handwritten-japanese-recognition-0001\n",
      "handwritten-score-recognition-0003\n",
      "handwritten-simplified-chinese-recognition-0001\n",
      "hbonet-0.25\n",
      "hbonet-1.0\n",
      "head-pose-estimation-adas-0001\n",
      "higher-hrnet-w32-human-pose-estimation\n",
      "horizontal-text-detection-0001\n",
      "hrnet-v2-c1-segmentation\n",
      "human-pose-estimation-0001\n",
      "human-pose-estimation-0005\n",
      "human-pose-estimation-0006\n",
      "human-pose-estimation-0007\n",
      "human-pose-estimation-3d-0001\n",
      "hybrid-cs-model-mri\n",
      "i3d-rgb-tf\n",
      "icnet-camvid-ava-0001\n",
      "icnet-camvid-ava-sparse-30-0001\n",
      "icnet-camvid-ava-sparse-60-0001\n",
      "image-retrieval-0001\n",
      "inception-resnet-v2-tf\n",
      "instance-segmentation-person-0007\n",
      "instance-segmentation-security-0002\n",
      "instance-segmentation-security-0091\n",
      "instance-segmentation-security-0228\n",
      "instance-segmentation-security-1039\n",
      "instance-segmentation-security-1040\n",
      "landmarks-regression-retail-0009\n",
      "levit-128s\n",
      "license-plate-recognition-barrier-0001\n",
      "license-plate-recognition-barrier-0007\n",
      "machine-translation-nar-de-en-0002\n",
      "machine-translation-nar-en-de-0002\n",
      "machine-translation-nar-en-ru-0002\n",
      "machine-translation-nar-ru-en-0002\n",
      "mask_rcnn_inception_resnet_v2_atrous_coco\n",
      "mask_rcnn_resnet50_atrous_coco\n",
      "midasnet\n",
      "mixnet-l\n",
      "mobilenet-v1-0.25-128\n",
      "mobilenet-v1-1.0-224-tf\n",
      "mobilenet-v2-1.0-224\n",
      "mobilenet-v2-1.4-224\n",
      "mobilenet-v2-pytorch\n",
      "mobilenet-v3-large-1.0-224-tf\n",
      "mobilenet-v3-small-1.0-224-tf\n",
      "mobilenet-yolo-v4-syg\n",
      "modnet-photographic-portrait-matting\n",
      "modnet-webcam-portrait-matting\n",
      "mozilla-deepspeech-0.6.1\n",
      "mozilla-deepspeech-0.8.2\n",
      "nanodet-m-1.5x-416\n",
      "nanodet-plus-m-1.5x-416\n",
      "netvlad-tf\n",
      "nfnet-f0\n",
      "noise-suppression-denseunet-ll-0001\n",
      "noise-suppression-poconetlike-0001\n",
      "open-closed-eye-0001\n",
      "pedestrian-and-vehicle-detector-adas-0001\n",
      "pedestrian-detection-adas-0002\n",
      "person-attributes-recognition-crossroad-0230\n",
      "person-attributes-recognition-crossroad-0234\n",
      "person-attributes-recognition-crossroad-0238\n",
      "person-detection-0106\n",
      "person-detection-0200\n",
      "person-detection-0201\n",
      "person-detection-0202\n",
      "person-detection-0203\n",
      "person-detection-0301\n",
      "person-detection-0302\n",
      "person-detection-0303\n",
      "person-detection-action-recognition-0005\n",
      "person-detection-action-recognition-0006\n",
      "person-detection-action-recognition-teacher-0002\n",
      "person-detection-asl-0001\n",
      "person-detection-raisinghand-recognition-0001\n",
      "person-detection-retail-0002\n",
      "person-detection-retail-0013\n",
      "person-reidentification-retail-0277\n",
      "person-reidentification-retail-0286\n",
      "person-reidentification-retail-0287\n",
      "person-reidentification-retail-0288\n",
      "person-vehicle-bike-detection-2000\n",
      "person-vehicle-bike-detection-2001\n",
      "person-vehicle-bike-detection-2002\n",
      "person-vehicle-bike-detection-2003\n",
      "person-vehicle-bike-detection-2004\n",
      "person-vehicle-bike-detection-crossroad-0078\n",
      "person-vehicle-bike-detection-crossroad-1016\n",
      "person-vehicle-bike-detection-crossroad-yolov3-1020\n",
      "product-detection-0001\n",
      "pspnet-pytorch\n",
      "quartznet-15x5-en\n",
      "regnetx-3.2gf\n",
      "repvgg-a0\n",
      "repvgg-b1\n",
      "repvgg-b3\n",
      "resnest-50-pytorch\n",
      "resnet-18-pytorch\n",
      "resnet-34-pytorch\n",
      "resnet-50-pytorch\n",
      "resnet-50-tf\n",
      "resnet18-xnor-binary-onnx-0001\n",
      "resnet50-binary-0001\n",
      "retinaface-resnet50-pytorch\n",
      "retinanet-tf\n",
      "rexnet-v1-x1.0\n",
      "rfcn-resnet101-coco-tf\n",
      "road-segmentation-adas-0001\n",
      "robust-video-matting-mobilenetv3\n",
      "semantic-segmentation-adas-0001\n",
      "shufflenet-v2-x1.0\n",
      "single-human-pose-estimation-0001\n",
      "single-image-super-resolution-1032\n",
      "single-image-super-resolution-1033\n",
      "smartlab-action-recognition-0001\n",
      "smartlab-object-detection-0001\n",
      "smartlab-object-detection-0002\n",
      "smartlab-object-detection-0003\n",
      "smartlab-object-detection-0004\n",
      "smartlab-sequence-modelling-0001\n",
      "smartlab-sequence-modelling-0002\n",
      "ssd-resnet34-1200-onnx\n",
      "ssd_mobilenet_v1_coco\n",
      "ssd_mobilenet_v1_fpn_coco\n",
      "ssdlite_mobilenet_v2\n",
      "swin-tiny-patch4-window7-224\n",
      "t2t-vit-14\n",
      "text-detection-0003\n",
      "text-detection-0004\n",
      "text-image-super-resolution-0001\n",
      "text-recognition-0012\n",
      "text-recognition-0014\n",
      "text-recognition-0015\n",
      "text-recognition-0016\n",
      "text-recognition-resnet-fc\n",
      "text-spotting-0005\n",
      "text-to-speech-en-0001\n",
      "text-to-speech-en-multi-0001\n",
      "time-series-forecasting-electricity-0001\n",
      "ultra-lightweight-face-detection-rfb-320\n",
      "ultra-lightweight-face-detection-slim-320\n",
      "unet-camvid-onnx-0001\n",
      "vehicle-attributes-recognition-barrier-0039\n",
      "vehicle-attributes-recognition-barrier-0042\n",
      "vehicle-detection-0200\n",
      "vehicle-detection-0201\n",
      "vehicle-detection-0202\n",
      "vehicle-detection-adas-0002\n",
      "vehicle-license-plate-detection-barrier-0106\n",
      "vehicle-license-plate-detection-barrier-0123\n",
      "vehicle-reid-0001\n",
      "vitstr-small-patch16-224\n",
      "wav2vec2-base\n",
      "wavernn\n",
      "weld-porosity-detection-0001\n",
      "yolact-resnet50-fpn-pytorch\n",
      "yolo-v1-tiny-tf\n",
      "yolo-v2-ava-0001\n",
      "yolo-v2-ava-sparse-35-0001\n",
      "yolo-v2-ava-sparse-70-0001\n",
      "yolo-v2-tf\n",
      "yolo-v2-tiny-ava-0001\n",
      "yolo-v2-tiny-ava-sparse-30-0001\n",
      "yolo-v2-tiny-ava-sparse-60-0001\n",
      "yolo-v2-tiny-tf\n",
      "yolo-v2-tiny-vehicle-detection-0001\n",
      "yolo-v3-onnx\n",
      "yolo-v3-tf\n",
      "yolo-v3-tiny-onnx\n",
      "yolo-v3-tiny-tf\n",
      "yolo-v4-tf\n",
      "yolo-v4-tiny-tf\n",
      "yolof\n",
      "yolox-tiny\n"
     ]
    }
   ],
   "source": [
    "!omz_downloader --print_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "459b8584-a077-443a-82d4-93dff0ade2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################|| Downloading face-detection-adas-0001 ||################\n",
      "\n",
      "========== Downloading C:\\BrainAI\\face-detection\\intel\\face-detection-adas-0001\\FP16\\face-detection-adas-0001.xml\n",
      "... 100%, 304 KB, 330 KB/s, 0 seconds passed\n",
      "\n",
      "========== Downloading C:\\BrainAI\\face-detection\\intel\\face-detection-adas-0001\\FP16\\face-detection-adas-0001.bin\n",
      "... 49%, 1024 KB, 753 KB/s, 1 seconds passed\n",
      "... 99%, 2048 KB, 1202 KB/s, 1 seconds passed\n",
      "... 100%, 2056 KB, 1196 KB/s, 1 seconds passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!omz_downloader --name face-detection-adas-0001 --precision FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "794ebef7-227e-4318-b32c-0029d28e6341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino as ov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "575295b4-1bc8-4b61-bb3c-fedea69321eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input layer shape:  [1,3,384,672]\n",
      "Output layer shape:  [1,1,200,7]\n"
     ]
    }
   ],
   "source": [
    "core = ov.Core()\n",
    "\n",
    "model = core.read_model(model=\"models/face-detection-adas-0001.xml\")\n",
    "face_model = core.compile_model(model=model, device_name=\"CPU\")\n",
    "\n",
    "face_input_layer = face_model.input(0)\n",
    "face_output_layer = face_model.output(0)\n",
    "print(\"Input layer shape: \", face_input_layer.shape)\n",
    "print(\"Output layer shape: \", face_output_layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "156dcf44-1954-477d-ba83-ef496f3b31dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(427, 500, 3)\n",
      "(1, 3, 384, 672)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread(\"data/test.jpg\")\n",
    "\n",
    "print(image.shape)\n",
    "\n",
    "resized_image = cv2.resize(src=image, dsize=(672, 384)) \n",
    "transposed_image = resized_image.transpose(2, 0, 1)\n",
    "input_image = np.expand_dims(transposed_image, 0)\n",
    "print(input_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de9ad460-b823-43dd-b9cb-60ca547dba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_output = face_model([input_image])[face_output_layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a076887-c67e-4442-b083-4c8f6e662d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.        , 1.        , 0.99949265, ..., 0.11505294,\n",
       "          0.7027575 , 0.8341556 ],\n",
       "         [0.        , 1.        , 0.03610478, ..., 0.29322466,\n",
       "          0.967311  , 0.41054735],\n",
       "         [0.        , 1.        , 0.03167792, ..., 0.7422958 ,\n",
       "          0.9306823 , 0.8740718 ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ]]]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0ad8b4e-7f91-4157-ac77-3f75378511ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.          1.          0.99949265  0.27355158  0.11505294  0.7027575   0.8341556 ]\n",
      "   [ 0.          1.          0.03610478  0.92736673  0.29322466  0.967311    0.41054735]\n",
      "   [ 0.          1.          0.03167792  0.86495376  0.7422958   0.9306823   0.8740718 ]\n",
      "   [ 0.          1.          0.02935363  0.9286659   0.38133153  0.97003186  0.51157695]\n",
      "   [ 0.          1.          0.0272578   0.93062055  0.34664917  0.9614588   0.42817008]\n",
      "   [ 0.          1.          0.02707244  0.8929478   0.31643856  0.9380208   0.44758946]\n",
      "   [ 0.          1.          0.02679225  0.87123394  0.62187403  0.937763    0.74589485]\n",
      "   [ 0.          1.          0.02613994  0.8460171   0.34094632  0.92966557  0.59182656]\n",
      "   [ 0.          1.          0.02581939  0.8929146   0.36850446  0.9361052   0.5000672 ]\n",
      "   [ 0.          1.          0.02554906  0.8265395   0.74258536  0.89098597  0.87097996]\n",
      "   [ 0.          1.          0.02541367  0.8448976   0.21641025  0.9322299   0.5101327 ]\n",
      "   [ 0.          1.          0.02485022  0.84993637  0.37504467  0.8957925   0.49569753]\n",
      "   [ 0.          1.          0.02467523  0.8698309   0.37011573  0.9180891   0.5106482 ]\n",
      "   [ 0.          1.          0.02403455  0.86273843  0.5212296   0.94910115  0.6981925 ]\n",
      "   [ 0.          1.          0.02398893  0.8943661   0.6007299   0.94075555  0.69778734]\n",
      "   [ 0.          1.          0.02372266  0.87297994  0.46948296  0.914182    0.57218724]\n",
      "   [ 0.          1.          0.02370207  0.84930515  0.3239687   0.8936695   0.4427747 ]\n",
      "   [ 0.          1.          0.02333843  0.870654    0.31518918  0.9207481   0.44750434]\n",
      "   [ 0.          1.          0.02286363  0.92778796  0.18743643  0.96724266  0.3279595 ]\n",
      "   [ 0.          1.          0.02278195  0.8638917   0.47749907  0.9334229   0.63270515]\n",
      "   [ 0.          1.          0.02213379  0.8902217   0.7257583   0.9541881   0.87826645]\n",
      "   [ 0.          1.          0.02196827  0.85276735  0.42999122  0.8995545   0.5477164 ]\n",
      "   [ 0.          1.          0.02175297  0.8929399   0.58559346  0.9687809   0.8128618 ]\n",
      "   [ 0.          1.          0.02135696  0.87676084  0.68293077  0.91636026  0.766614  ]\n",
      "   [ 0.          1.          0.02129442  0.8886846   0.41507638  0.9361574   0.54576975]\n",
      "   [ 0.          1.          0.02112406  0.7143827   0.02708684  0.9296376   0.49011528]\n",
      "   [ 0.          1.          0.02104482  0.82591456  0.3933112   0.86161155  0.47367162]\n",
      "   [ 0.          1.          0.02071763  0.8347082   0.5157321   0.91355133  0.6838544 ]\n",
      "   [ 0.          1.          0.02069757  0.87588465  0.6458707   0.9176644   0.72719324]\n",
      "   [ 0.          1.          0.02049972  0.87789804  0.4125618   0.90622705  0.4635158 ]\n",
      "   [ 0.          1.          0.02028497  0.9044115   0.40737522  0.9299081   0.4705636 ]\n",
      "   [ 0.          1.          0.0201073   0.86856025  0.2353055   0.91989046  0.38865077]\n",
      "   [ 0.          1.          0.02004304  0.87772113  0.45397392  0.90482205  0.51815593]\n",
      "   [ 0.          1.          0.02003042  0.6771395   0.3862905   0.7378906   0.5218433 ]\n",
      "   [ 0.          1.          0.0199964   0.86727977  0.12331716  0.91653156  0.29183283]\n",
      "   [ 0.          1.          0.0198868   0.81672186  0.5541999   0.8872853   0.70265645]\n",
      "   [ 0.          1.          0.01976793  0.87537414  0.60264957  0.92063767  0.6926093 ]\n",
      "   [ 0.          1.          0.01972752  0.8501902   0.24090779  0.89502007  0.37454158]\n",
      "   [ 0.          1.          0.01969075  0.8600863   0.67237395  0.950443    0.8488553 ]\n",
      "   [ 0.          1.          0.01943995  0.8257459   0.08211011  0.87033683  0.23734242]\n",
      "   [ 0.          1.          0.01934608  0.84891695  0.48887545  0.8979723   0.6158579 ]\n",
      "   [ 0.          1.          0.01932282  0.9112433   0.5440674   0.96529293  0.6847302 ]\n",
      "   [ 0.          1.          0.0193016   0.90407515  0.36333326  0.9308585   0.42342064]\n",
      "   [ 0.          1.          0.0191673   0.8248808   0.4794829   0.8616423   0.5673238 ]\n",
      "   [ 0.          1.          0.01911571  0.7938668   0.2840885   0.852717    0.43479323]\n",
      "   [ 0.          1.          0.01910282  0.80356675  0.47338328  0.8489494   0.58555114]\n",
      "   [ 0.          1.          0.01909736  0.7382391   0.10819249  0.834266    0.30943853]\n",
      "   [ 0.          1.          0.01907908  0.72787684  0.43964693  0.7598875   0.51880044]\n",
      "   [ 0.          1.          0.01892103  0.90406674  0.32332215  0.931078    0.38576886]\n",
      "   [ 0.          1.          0.0189196   0.8425466   0.6193874   0.89950633  0.729666  ]\n",
      "   [ 0.          1.          0.01880481  0.78221613  0.4049074   0.8144532   0.4824431 ]\n",
      "   [ 0.          1.          0.01879148  0.82183576  0.42889318  0.8670651   0.5399325 ]\n",
      "   [ 0.          1.          0.01874825  0.81283295  0.31506124  0.877077    0.46477488]\n",
      "   [ 0.          1.          0.01872677  0.9031655   0.44542372  0.929678    0.5099904 ]\n",
      "   [ 0.          1.          0.0187105   0.71744716  0.23247048  0.8495898   0.5220429 ]\n",
      "   [ 0.          1.          0.01865134  0.7221323   0.45641345  0.76801395  0.57183236]\n",
      "   [ 0.          1.          0.01860647  0.87951946  0.32046857  0.9056417   0.38698074]\n",
      "   [ 0.          1.          0.01843905  0.7051611   0.39749378  0.76597047  0.5498056 ]\n",
      "   [ 0.          1.          0.01834436  0.83049107  0.36301032  0.85853076  0.427897  ]\n",
      "   [ 0.          1.          0.01834168  0.71596694  0.37233183  0.7457912   0.42630497]\n",
      "   [ 0.          1.          0.01833685  0.66572225  0.45314106  0.6945405   0.506413  ]\n",
      "   [ 0.          1.          0.01826717  0.64208233  0.37093836  0.6667901   0.42182958]\n",
      "   [ 0.          1.          0.01822911  0.78126305  0.43791303  0.814416    0.52189326]\n",
      "   [ 0.          1.          0.01819568  0.80844885  0.36228326  0.8373944   0.42936632]\n",
      "   [ 0.          1.          0.01817933  0.74097204  0.41053364  0.8019625   0.5580488 ]\n",
      "   [ 0.          1.          0.0181527   0.834054    0.677498    0.89225364  0.7947371 ]\n",
      "   [ 0.          1.          0.01815233  0.66194934  0.40394267  0.6978175   0.47043833]\n",
      "   [ 0.          1.          0.01811747  0.8602582   0.16607353  0.9875386   0.54412174]\n",
      "   [ 0.          1.          0.01806787  0.7985626   0.35917652  0.859047    0.49987382]\n",
      "   [ 0.          1.          0.01806242  0.874214    0.36848682  0.9788242   0.55366224]\n",
      "   [ 0.          1.          0.01805351  0.79780483  0.24146996  0.8695632   0.494668  ]\n",
      "   [ 0.          1.          0.01797576  0.6644596   0.3699878   0.6939604   0.41993785]\n",
      "   [ 0.          1.          0.01797351  0.7818274   0.47534335  0.81520456  0.5620905 ]\n",
      "   [ 0.          1.          0.01797268  0.6532975   0.38402182  0.7143964   0.49232626]\n",
      "   [ 0.          1.          0.01794642  0.90331817  0.69678533  0.93053496  0.76165617]\n",
      "   [ 0.          1.          0.01793045  0.83047074  0.44956353  0.8586146   0.51207626]\n",
      "   [ 0.          1.          0.01791544  0.8035669   0.43062398  0.8491307   0.5374089 ]\n",
      "   [ 0.          1.          0.01788777  0.7913135   0.5224416   0.8550507   0.66187537]\n",
      "   [ 0.          1.          0.01788266  0.8802722   0.36309242  0.9056832   0.4260515 ]\n",
      "   [ 0.          1.          0.01783268  0.7083139   0.39666218  0.7427195   0.48227757]\n",
      "   [ 0.          1.          0.01781113  0.63138133  0.35329697  0.6775232   0.44917282]\n",
      "   [ 0.          1.          0.01780375  0.79810274  0.5089576   0.8706536   0.7444855 ]\n",
      "   [ 0.          1.          0.01766424  0.831435    0.6180675   0.8613009   0.67366374]\n",
      "   [ 0.          1.          0.01763331  0.8573173   0.45205295  0.8844001   0.5144623 ]\n",
      "   [ 0.          1.          0.01760818  0.8255206   0.21270922  0.86596256  0.33667156]\n",
      "   [ 0.          1.          0.01759885  0.9300165   0.40437475  0.95636845  0.470243  ]\n",
      "   [ 0.          1.          0.01755971  0.81863016  0.49388543  0.8668104   0.6143969 ]\n",
      "   [ 0.          1.          0.01755335  0.93488574  0.40695184  0.9788109   0.56377393]\n",
      "   [ 0.          1.          0.01752131  0.6612818   0.48270586  0.6987845   0.5548924 ]\n",
      "   [ 0.          1.          0.01751551  0.5567133   0.8045269   0.60979897  0.9242891 ]\n",
      "   [ 0.          1.          0.01742479  0.82631224  0.29555506  0.9608689   0.44424683]\n",
      "   [ 0.          1.          0.0173964   0.88854426  0.22184105  0.9630652   0.51232404]\n",
      "   [ 0.          1.          0.01738702  0.9188439   0.4826526   0.96892935  0.6075198 ]\n",
      "   [ 0.          1.          0.01729973  0.8775116   0.49110723  0.90637636  0.5537503 ]\n",
      "   [ 0.          1.          0.01727522  0.6706753   0.44580123  0.73654425  0.55699855]\n",
      "   [ 0.          1.          0.0172435   0.821731    0.29592025  0.86521125  0.41533232]\n",
      "   [ 0.          1.          0.01723513  0.85567623  0.15161985  0.9281748   0.3717351 ]\n",
      "   [ 0.          1.          0.01723162  0.6342543   0.4438024   0.67134184  0.50703317]\n",
      "   [ 0.          1.          0.0172288   0.68472916  0.40256     0.7234785   0.48724937]\n",
      "   [ 0.          1.          0.01720695  0.6315208   0.32082877  0.7228729   0.4777948 ]\n",
      "   [ 0.          1.          0.01720653  0.8570793   0.36270487  0.8832392   0.4250695 ]\n",
      "   [ 0.          1.          0.01717039  0.80787253  0.3243669   0.8365352   0.39012095]\n",
      "   [ 0.          1.          0.01716943  0.80803245  0.5351152   0.8365796   0.59392494]\n",
      "   [ 0.          1.          0.01716745  0.80897874  0.4896883   0.8375208   0.55479944]\n",
      "   [ 0.          1.          0.01713561  0.92703706  0.43493846  0.96098214  0.5318357 ]\n",
      "   [ 0.          1.          0.01712676  0.9025296   0.6146438   0.93071604  0.6781988 ]\n",
      "   [ 0.          1.          0.01709077  0.6341525   0.40626928  0.6691558   0.46659645]\n",
      "   [ 0.          1.          0.01707365  0.83069795  0.648085    0.8657207   0.7219819 ]\n",
      "   [ 0.          1.          0.01703648  0.6512156   0.348198    0.7079194   0.44493133]\n",
      "   [ 0.          1.          0.01703413  0.63754624  0.39355168  0.72920173  0.55176795]\n",
      "   [ 0.          1.          0.01699558  0.85703     0.32164234  0.88358885  0.387281  ]\n",
      "   [ 0.          1.          0.01687713  0.62647295  0.4589908   0.6823207   0.5982349 ]\n",
      "   [ 0.          1.          0.01685039  0.87423426  0.724787    0.91462487  0.8106284 ]\n",
      "   [ 0.          1.          0.01684841  0.67370474  0.35709262  0.7299733   0.46732426]\n",
      "   [ 0.          1.          0.01684743  0.7160032   0.49059832  0.78327084  0.652756  ]\n",
      "   [ 0.          1.          0.01680179  0.8206822   0.65233374  0.91018385  0.8218782 ]\n",
      "   [ 0.          1.          0.01677043  0.8780194   0.6204763   0.9095184   0.67387515]\n",
      "   [ 0.          1.          0.01676811  0.85544     0.397828    0.88776696  0.47326288]\n",
      "   [ 0.          1.          0.01673115  0.77343315  0.55055106  0.81909794  0.65776014]\n",
      "   [ 0.          1.          0.01663736  0.8091911   0.40384576  0.83815384  0.46754953]\n",
      "   [ 0.          1.          0.01662598  0.6493626   0.15743767  0.7292327   0.4419908 ]\n",
      "   [ 0.          1.          0.01660616  0.7799167   0.19948591  0.910968    0.52222776]\n",
      "   [ 0.          1.          0.01660218  0.8178307   0.23042965  0.8798878   0.3977884 ]\n",
      "   [ 0.          1.          0.01658912  0.68485785  0.46731153  0.7215493   0.5478425 ]\n",
      "   [ 0.          1.          0.01656373  0.8734945   0.13319105  0.90947783  0.22357607]\n",
      "   [ 0.          1.          0.01656193  0.93210304  0.26934287  0.96220255  0.35592803]\n",
      "   [ 0.          1.          0.01649211  0.87963426  0.57397896  0.9070015   0.635197  ]\n",
      "   [ 0.          1.          0.01647342  0.75993925  0.45308363  0.78852755  0.5092984 ]\n",
      "   [ 0.          1.          0.0164387   0.6199637   0.38714567  0.67897075  0.48437294]\n",
      "   [ 0.          1.          0.01639839  0.6034495   0.45542628  0.6579898   0.5810748 ]\n",
      "   [ 0.          1.          0.01639587  0.7683151   0.4565302   0.8255563   0.6006491 ]\n",
      "   [ 0.          1.          0.01638733  0.6106107   0.44524208  0.6481664   0.50612   ]\n",
      "   [-1.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]\n",
      "   [ 0.          0.          0.          0.          0.          0.          0.        ]]]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold=np.inf, linewidth=np.inf)\n",
    "print(face_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ace57b17-cc9f-41aa-b1db-aeb609de7719",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(edgeitems=3, infstr='inf', linewidth=75, nanstr='nan', precision=8, suppress=False, threshold=1000, formatter=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f25a5934-5284-4dad-a2c1-634e8b3ae070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.        , 1.        , 0.99949265, ..., 0.11505294,\n",
       "          0.7027575 , 0.8341556 ],\n",
       "         [0.        , 1.        , 0.03610478, ..., 0.29322466,\n",
       "          0.967311  , 0.41054735],\n",
       "         [0.        , 1.        , 0.03167792, ..., 0.7422958 ,\n",
       "          0.9306823 , 0.8740718 ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ]]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0cf904b-1263-45e3-8be4-d6dafb59dbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#추론한 값(output), 이미지(image), 임계값(conf)을 가져와 \n",
    "#이미지에 얼굴에 박스를 그리는 DrawBoundingBoxes함수\n",
    "def DrawBoundingBoxes(output, image, conf):\n",
    "\n",
    "    canvas = image.copy()\n",
    "    h,w,_ = canvas.shape \n",
    "\n",
    "    predictions = output[0][0]            # 하위 집합 데이터 프레임\n",
    "    confidence = predictions[:,2]         # conf 값 가져오기 [image_id, label, conf, x_min, y_min, x_max, y_max]\n",
    "\n",
    "    top_predictions = predictions[(confidence>conf)]         # 임계값보다 큰 conf 값을 가진 예측만 선택\n",
    "\n",
    "    for detection in top_predictions:\n",
    "        box = detection[3:7] * np.array([w, h, w, h]) # 상자 위치 결정\n",
    "        (xmin, ymin, xmax, ymax) = box.astype(\"int\")  # xmin, ymin, xmax, ymax에 상자 위치 값 지정\n",
    "\n",
    "        cv2.rectangle(canvas, (xmin, ymin), (xmax, ymax), (0, 0, 255), 2)       # 사각형 만들기\n",
    "\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48cc81f7-5f02-42cf-bee5-bcf250a646f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = DrawBoundingBoxes(face_output, image, conf=0.5)\n",
    "cv2.imshow(\"Canvas\", canvas)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d47d7620-128a-4e71-ba37-69b34666a54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino as ov\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# AI 모델 불러오기 ,input_layer & output_layer 준비\n",
    "core = ov.Core()\n",
    "model = core.read_model(model=\"models/face-detection-adas-0001.xml\")\n",
    "face_model = core.compile_model(model=model, device_name=\"CPU\")\n",
    "face_input_layer = face_model.input(0)\n",
    "face_output_layer = face_model.output(0)\n",
    "\n",
    "# 새로 입력된 이미지 데이터 전처리\n",
    "def preprocess(new_image):\n",
    "    # Convert the PIL image to a NumPy array and resize to 224x224\n",
    "    #image = np.array(new_image)  # Convert PIL image to numpy array\n",
    "    resized_image = cv2.resize(src=new_image, dsize=(672, 384)) \n",
    "    transposed_image = resized_image.transpose(2, 0, 1)\n",
    "    input_image = np.expand_dims(transposed_image, 0)\n",
    "    return input_image\n",
    "\n",
    "# AI 추론 결과 후처리: 시각화(인식된 얼굴 주변에 박스 그리기)\n",
    "def DrawBoundingBoxes(new_image, face_output, conf):\n",
    "    canvas = new_image.copy()\n",
    "    h,w,_ = canvas.shape \n",
    "    predictions = face_output[0][0]            # 하위 집합 데이터 프레임\n",
    "    confidence = predictions[:,2]         # conf 값 가져오기 [image_id, label, conf, x_min, y_min, x_max, y_max]\n",
    "    top_predictions = predictions[(confidence>conf)]         # 임계값보다 큰 conf 값을 가진 예측만 선택\n",
    "    for detection in top_predictions:\n",
    "        box = detection[3:7] * np.array([w, h, w, h]) # 상자 위치 결정\n",
    "        (xmin, ymin, xmax, ymax) = box.astype(\"int\")  # xmin, ymin, xmax, ymax에 상자 위치 값 지정\n",
    "        cv2.rectangle(canvas, (xmin, ymin), (xmax, ymax), (0, 0, 255), 2)       # 사각형 만들기\n",
    "    return canvas\n",
    "\n",
    "# AI 추론\n",
    "def predict_image(new_image):\n",
    "    input_image = preprocess(new_image)  # Preprocess the image\n",
    "    face_output = face_model([input_image])[face_output_layer]  # Perform inference  \n",
    "    canvas = DrawBoundingBoxes(new_image, face_output, conf=0.5)\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "622cbe5d-b467-4a87-b8d8-ee05d12e9ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CPU', 'GPU']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openvino as ov\n",
    "\n",
    "core = ov.Core()\n",
    "options=core.available_devices\n",
    "options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cb14ea4-fb40-44a6-985c-9030604ed62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino as ov\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# AI 모델 불러오기 ,input_layer & output_layer 준비\n",
    "core = ov.Core()\n",
    "model = core.read_model(model=\"models/face-detection-adas-0001.xml\")\n",
    "face_model = core.compile_model(model=model, device_name=\"CPU\")\n",
    "face_input_layer = face_model.input(0)\n",
    "face_output_layer = face_model.output(0)\n",
    "\n",
    "# 새로 입력된 이미지 데이터 전처리\n",
    "def preprocess(new_image):\n",
    "    # Convert the PIL image to a NumPy array and resize to 224x224\n",
    "    #image = np.array(new_image)  # Convert PIL image to numpy array\n",
    "    resized_image = cv2.resize(src=new_image, dsize=(672, 384)) \n",
    "    transposed_image = resized_image.transpose(2, 0, 1)\n",
    "    input_image = np.expand_dims(transposed_image, 0)\n",
    "    return input_image\n",
    "\n",
    "# AI 추론 결과 후처리: 시각화(인식된 얼굴 주변에 박스 그리기)\n",
    "def DrawBoundingBoxes(new_image, face_output, conf):\n",
    "    canvas = new_image.copy()\n",
    "    h,w,_ = canvas.shape \n",
    "    predictions = face_output[0][0]            # 하위 집합 데이터 프레임\n",
    "    confidence = predictions[:,2]         # conf 값 가져오기 [image_id, label, conf, x_min, y_min, x_max, y_max]\n",
    "    top_predictions = predictions[(confidence>conf)]         # 임계값보다 큰 conf 값을 가진 예측만 선택\n",
    "    for detection in top_predictions:\n",
    "        box = detection[3:7] * np.array([w, h, w, h]) # 상자 위치 결정\n",
    "        (xmin, ymin, xmax, ymax) = box.astype(\"int\")  # xmin, ymin, xmax, ymax에 상자 위치 값 지정\n",
    "        cv2.rectangle(canvas, (xmin, ymin), (xmax, ymax), (0, 0, 255), 2)       # 사각형 만들기\n",
    "    return canvas\n",
    "\n",
    "# AI 추론\n",
    "def predict_image(new_image):\n",
    "    input_image = preprocess(new_image)  # Preprocess the image\n",
    "    face_output = face_model([input_image])[face_output_layer]  # Perform inference  \n",
    "    canvas = DrawBoundingBoxes(new_image, face_output, conf=0.5)\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65fc7b76-0204-434f-a43c-b56f793f0ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Gradio 실행\n",
    "gr.Interface(fn=predict_image,\n",
    "             inputs=gr.Image(type=\"numpy\"),  # Use NumPy array\n",
    "             outputs=gr.Image(type=\"numpy\"),  # Output as NumPy array\n",
    "             examples=[\"./data/test.jpg\"]).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a3ca27a-ba22-434c-b357-053f95fe413d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'destroyALLWindows'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcam\u001b[39m\u001b[38;5;124m'\u001b[39m, frame)\n\u001b[0;32m      7\u001b[0m cam\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m----> 8\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyALLWindows()\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'destroyALLWindows'"
     ]
    }
   ],
   "source": [
    "cam=cv2.VideoCapture(0)\n",
    "while cv2.waitKey(33)<0 :\n",
    "    ret, frame = cam.read()\n",
    "    frame = predict_image(frame)\n",
    "\n",
    "    cv2.imshow('cam', frame)\n",
    "cam.release()\n",
    "cv2.destroyALLWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932a3c32-c7c6-41ee-be40-b2b77ee2a016",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = \"./images/Background.jpg\"  #사용할 배경화면 경로\n",
    "canvas = DrawBoundingBoxes(face_output, frame, conf=0.5)  \n",
    "bg = cv2.imread(background)\n",
    "\n",
    "deployment = AddBackground(canvas, bg)\n",
    "cv2.imshow(\"Deployment\", deployment)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7550c5b1-ebba-4f81-a510-254318774e69",
   "metadata": {},
   "outputs": [],
   "source": [
    " camera = cv2.VideoCapture(0) #create a VideoCapture object with the 'first' camera (your webcam)\n",
    "\n",
    "while(True):\n",
    "    ret, frame = camera.read()             # Capture frame by frame      \n",
    "    if ret == False:\n",
    "        break\n",
    "    \n",
    "    resized_frame = cv2.resize(src=frame, dsize=(672, 384)) \n",
    "    transposed_frame = resized_frame.transpose(2, 0, 1)\n",
    "    input_frame = np.expand_dims(transposed_frame, 0)    \n",
    "    \n",
    "    face_output = face_model([input_frame])[face_output_layer]\n",
    "\n",
    "    canvas = DrawBoundingBoxes(face_output, frame, conf=0.5)\n",
    "    \n",
    "    cv2.imshow('Press Spacebar to Exit', canvas)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(' '):  # Stop if spacebar is detected\n",
    "        break\n",
    "\n",
    "camera.release()                           # Cleanup after spacebar is detected.\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed1286e-9a81-43c4-99b7-48c4e9acc82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = cv2.VideoCapture(0) #create a VideoCapture object with the 'first' camera (your webcam)\n",
    "background = \"./images/Background.jpg\"\n",
    "bg = cv2.imread(background)\n",
    "\n",
    "while(True):\n",
    "    ret, frame = camera.read()             # Capture frame by frame      \n",
    "    if ret == False:\n",
    "        break\n",
    "    \n",
    "    resized_frame = cv2.resize(src=frame, dsize=(672, 384)) \n",
    "    transposed_frame = resized_frame.transpose(2, 0, 1)\n",
    "    input_frame = np.expand_dims(transposed_frame, 0)    \n",
    "    \n",
    "    face_output = face_model([input_frame])[face_output_layer]\n",
    "\n",
    "    canvas = DrawBoundingBoxes(face_output, frame, conf=0.5)\n",
    "    deployment = AddBackground(canvas, bg)\n",
    "    \n",
    "    cv2.imshow('Press Spacebar to Exit', deployment)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(' '):  # Stop if spacebar is detected\n",
    "        break\n",
    "\n",
    "camera.release()                           # Cleanup after spacebar is detected.\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
